# Speech



Hello everyone, my name is xxx and my supervisor is xxx

The topic I want to give is [title]



---

I will first introduce the background of generative adversarial networks

and then my research problem of conditional GAN

Before my own work, I will give an overview of related work

Finally, is my conclusion.

---

Take a quick look at two pictures, one is a real face image, and the other is a fake image generated by GAN

Which face do you think is real?

Oh, actually the right face is real. 



This is the state of the art example of GAN

---

And here, Prof. Yann had say that xxx

An art painting generated by GAN sold for $400 thousand at Christie's

the technology of GAN also is used in Adobe photoshop

---



After we have established a perceptual understanding of GAN, we should start to talk about some details

---



Let's begin with the explanation of GAN. You may have always heard of this item.

G is from Generative, which means the purpose or the result is to get new synthetic instance of data.

A is from Adversarial, this framework is composed by two parts: a generator and a discriminator. they want to fight with each others. generator want to generate fake data to fool discriminator, but the discriminator doesn't want to be fooled. So it's a adversarial process.

N is from Networks, which means the generator and discriminator are represented by neural networks.

---



A good expression of GAN is made by Silva

we can see that the generator turns a random noise into a fake data

and then the discriminator will distinguish the fake data and the real data

Their respective losses will help them get better

---



The details of GAN can be also represented by this diagram

I will use this unified form in my whole report.



we first Sample...



We can use this two max function to update the discriminator and generator,  the Intuitive understanding is that the role of D is scoring. Here, We want to give high marks to the real samples and low marks to the fake samples. And here, we want to give high marks to the fake samples.

---



One of the problem of GAN is that we get a projection from latent space z to observe space x.

We can not control the output of GAN,

However, in the real world, for example, the real data has two categories, we want to control the output to generate each categories.

---



How to make it, actually the latent space are entangled with each other, maybe several dims of z control a same feature dim. if we want to make GAN controllable, we need to disentangle. After that, we can control one feature by modifying one dim of z.

---



The detail of CGAN is here, 

The first two steps are the same, but here we need a pair of real data with a label 



判别器现在需要给三个部分打分，匹配对的真样本打高分，匹配对的假样本打低分，匹配不对的真样本打高分，

The discriminator now has to score three parts, high on the true samples of the matched pairs, low on the false samples of the matched pairs, high on the true samples of the mismatched pairs,



the function of generator is the same.

---

To introduce a new framework, here is a supplementary point about semi-supervised learning

On the left, Traditional supervised learning is data with labels, there two cycles are labeled by two colors. we can easily train a classifier to classify there two parts. 

On the right, here we only have few labeled data, we first use the unlabeled data to train to cluster two parts, and Then use a limited amount of labeled data to do the classifier

We can use GAN to generate more unlabeled data to achieve semi-supervised learning

---



This is the detail of Semi-supervised GAN, 

D of CGAN is still a binary classification work. We are wondering whether D can classify the label of data while distinguishing true and false data

Traditional GAN extracts features that distinguish between true and false, while CGAN extracts features that distinguish between pair pictures. Now, one task is to extract true and false features, while the other task is to extract label classification features.
These two tasks can be done at the same time, and both work will be better.
Finally we will get a balance between the three.



The details here are similar, so will not read them anymore

The difference in update function is that we use a multi-class cross entropy to replace binary cross entropy.



However, SGAN does not achieve the effect of CGAN, but only makes G perform better

---



can we get the advantage of SGAN and achieve controllable GAN at the same time?

So we use two networks to achieve them separately

C means a classifier, and write it with D because they share the weight partially 



The update function of discriminator is same

The update function of classifier, we want to give high mark to real samples with correct labels, give low mark to real samples with incorrect labels, and give high mark to fake samples with correct labels.

The update function of generator is that we want to give high mark to both fake samples and fake samples with correct labels.

---



After I have introduce the related work,

My motivation is that Which is better to get, a label or a trained model

 

Then can we generate US female face with only the data of male face 

can we use a gender classifier trained by Chinese male face and female face. because the gender feature is similar of same.



And can we use a moon classifier to add moon into a landscape image?

---



With this in mind, I propose a new framework of Multi-objective GAN

we use a trained model, this trained model has learn the feature extracting, So it can add new feature to original data which do not have the feature.



For an example, if in all data, the subject are in the center, and then the position is not a feature, but a trained model can help add the controllable feature.



and the function is simple, we only need to add a classifier loss to generator.

---

This is a comparation between these related GAN framework.

